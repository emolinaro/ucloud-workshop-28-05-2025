{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <a href=\"https://escience.sdu.dk/index.php/ucloud/\">\n",
    "    <img src=\"https://escience.sdu.dk/wp-content/uploads/2020/03/logo_esc.svg\" width=\"400\" height=\"186\" />\n",
    "  </a>\n",
    "</center>\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em;\">\n",
    "  This notebook was tested against an instance of <strong>Label Studio v1.16.0</strong> running on UCloud.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Curating a Medical Q&A Dataset with Label Studio\n",
    "\n",
    "This tutorial guides you through the process of creating a high-quality dataset for a Generative AI model, with a focus on medical Q&A generation. \n",
    "You'll learn how to set up projects in Label Studio, import datasets, and configure tasks to streamline the annotation process.\n",
    "\n",
    "### ‚úÖ **Prerequisites**\n",
    "- üöÄ Start a Label Studio instance on UCloud:\n",
    "    - Import the `label-studio` folder in this repository as the Label Studio database directory.\n",
    "    - [Connect](https://docs.cloud.sdu.dk/guide/submitting.html#connect-to-other-jobs) this Label Studio instance to the **Triton Inference Server** job serving the distributed **Llama 3.1 Nemotron Nano 4B v1.1** model.\n",
    "        - Use `triton` as *hostname* when selecting the job.\n",
    "- üìò Launch this notebook in an IDE on UCloud (e.g., JupyterLab or Coder):\n",
    "    - Ensure the notebook can connect to the previously started Label Studio instance.\n",
    "        - Use `label-studio` as the hostname when connecting to the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 1: Install Label-Studio SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets==3.4.1 label-studio-sdk==1.0.11 python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 2: Setup Label Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from label_studio_sdk.client import LabelStudio\n",
    "\n",
    "# Load environment variables from label-studio/.env\n",
    "dotenv_path = os.path.join(\"label-studio\", \".env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Retrieve Label Studio SECRET key from the environment variables\n",
    "LABEL_STUDIO_URL = \"http://label-studio:8080\"\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API_KEY not found in the environment file!\")\n",
    "\n",
    "# Connect to the Label Studio API\n",
    "client = LabelStudio(base_url=LABEL_STUDIO_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 3: Question Generation with MeDAL\n",
    "\n",
    "The [MeDAL dataset](https://huggingface.co/datasets/medal) is a large medical text dataset curated from over 14 million abstracts from PubMed publications.\n",
    "\n",
    "We can leverage this dataset to establish context for generating a synthetic Q&A dataset. To begin, we'll set up a Label Studio project for question generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_question_config = \"\"\"\n",
    "<View className=\"root\">\n",
    "  <Style>\n",
    "  .root {\n",
    "    font-family: 'Roboto', sans-serif;\n",
    "    line-height: 1.6;\n",
    "    background-color: #f0f0f0;\n",
    "  }\n",
    "  .container {\n",
    "    margin: 0 auto;\n",
    "    padding: 20px;\n",
    "    background-color: #ffffff;\n",
    "    border-radius: 5px;\n",
    "    box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.1), 0 6px 20px 0 rgba(0, 0, 0, 0.1);\n",
    "  }\n",
    "  .prompt {\n",
    "    padding: 20px;\n",
    "    background-color: #0084ff;\n",
    "    color: #ffffff;\n",
    "    border-radius: 5px;\n",
    "    margin-bottom: 20px;\n",
    "    box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1), 0 3px 10px 0 rgba(0, 0, 0, 0.1);\n",
    "  }\n",
    "  .prompt-input {\n",
    "    flex-basis: 49%;\n",
    "    padding: 20px;\n",
    "    background-color: rgba(44, 62, 80, 0.9);\n",
    "    color: #ffffff;\n",
    "    border-radius: 5px;\n",
    "    box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1), 0 3px 10px 0 rgba(0, 0, 0, 0.1);\n",
    "    width: 100%;\n",
    "    border: none;\n",
    "    font-family: 'Roboto', sans-serif;\n",
    "    font-size: 16px;\n",
    "    outline: none;\n",
    "  }\n",
    "  .prompt-input:focus {\n",
    "    outline: none;\n",
    "  }\n",
    "  .prompt-input:hover {\n",
    "    background-color: rgba(52, 73, 94, 0.9);\n",
    "    cursor: pointer;\n",
    "    transition: all 0.3s ease;\n",
    "  }\n",
    "  .lsf-richtext__line:hover {\n",
    "    background: unset;\n",
    "  }\n",
    "  </Style>\n",
    "  <Text name=\"chat\" value=\"$text\" layout=\"dialogue\"/>\n",
    "  <Header value=\"Question prompt:\"/>\n",
    "  <View className=\"prompt\">\n",
    "    <TextArea name=\"prompt\" toName=\"chat\" rows=\"4\" editable=\"true\" maxSubmissions=\"1\" showSubmitButton=\"false\"/>\n",
    "  </View>\n",
    "  <Header value=\"Proposed questions:\"/>\n",
    "  <TextArea name=\"response\" toName=\"chat\" rows=\"3\" editable=\"true\" maxSubmissions=\"1\" showSubmitButton=\"false\"/>\n",
    "</View>\n",
    "\"\"\"\n",
    "\n",
    "medal_questions_project = client.projects.create(\n",
    "    title='MeDAL Question Generation',\n",
    "    color='#ECB800',\n",
    "    description='',\n",
    "    label_config=medal_question_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and import it into Label Studio. Since the dataset is quite large, we'll start by loading only a subset of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "medal_train_dataset = load_dataset(\"medal\", split='train', cache_dir=\"datasets\")\n",
    "medal_validation_dataset = load_dataset(\"medal\", split='validation', cache_dir=\"datasets\")\n",
    "medal_test_dataset = load_dataset(\"medal\", split='validation', cache_dir=\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_train_dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert examples into Label Studio\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_examples = 10000\n",
    "\n",
    "for i in tqdm(range(num_examples), desc=\"Uploading tasks\"):\n",
    "    task = medal_train_dataset[i]\n",
    "    client.tasks.create(\n",
    "        project=medal_questions_project.id,\n",
    "        data=task\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For question generation, we need to have a strong prompt to yield solid results. Here is a useful prompt for generating medical questions for examples from the MeDAL dataset.\n",
    "\n",
    "```txt\n",
    "Given a block of medical text, generate several direct, succinct, and unique questions that stand alone, focusing on extracting specific medical information such as symptoms, diagnosis, treatment options, or patient management strategies. Each question should aim to elicit precise and informative responses without requiring additional context. The questions should cover diverse aspects of the medical content to ensure a comprehensive understanding. Ensure each question is clear and formulated to be self-contained. Here are examples to guide your question generation:\n",
    "\n",
    "What are the common symptoms associated with [specific condition]?\n",
    "How is [specific condition] diagnosed?\n",
    "What treatment options are available for [specific condition]?\n",
    "What are the potential side effects of [specific medication]?\n",
    "What preventive measures are recommended for [specific condition]?\n",
    "\n",
    "Use these examples as a template, tailoring questions to different parts of the text to maximize the dataset's utility and accuracy. Questions must be separated by a new line without any markers or numbers. Do not output any text before and after the questions. Generate up to 5 questions. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß To set up the ML Backend, open the Label Studio terminal interface and run the commands:\n",
    "```bash\n",
    "$ cd /work/label-studio/ml_backend\n",
    "$ pip install -r requirements.txt\n",
    "$ source setup_questions.sh\n",
    "$ gunicorn _wsgi:app --bind 0.0.0.0:9090 --workers 10 --timeout 120 --graceful-timeout 30 --keep-alive 5\n",
    "```\n",
    "This will launch a new ML backend configured for generating questions. [Load the ML backend server](https://docs.cloud.sdu.dk/Apps/label-studio.html#load-the-model) into the Label Studio project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk import Client\n",
    "\n",
    "def get_project_task_ids(label_studio_host, api_token, project_id):\n",
    "    client = Client(url=label_studio_host, api_key=api_token)\n",
    "    project = client.get_project(project_id)\n",
    "    task_ids = project.get_tasks_ids()\n",
    "    return task_ids\n",
    "\n",
    "project_id = medal_questions_project.id\n",
    "\n",
    "tasks_ids = get_project_task_ids(LABEL_STUDIO_URL, API_KEY, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tasks_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def retrieve_batch_predictions(project_id, task_ids, api_key):\n",
    "    url = f\"{LABEL_STUDIO_URL}/api/dm/actions?id=retrieve_tasks_predictions&project={project_id}\"\n",
    "    headers = {\n",
    "        'Authorization': f'Token {api_key}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    data = {\n",
    "        'selectedItems': {\n",
    "            'all': False,\n",
    "            'included': task_ids\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "batch_size   = 15 # compare with Triton Server MAX_BATCH_SIZE\n",
    "start_index  = 0\n",
    "end_index    = 10000\n",
    "max_workers  = 8   # tune this based on how many parallel requests your server can handle\n",
    "project_id = medal_questions_project.id\n",
    "\n",
    "def submit_batches(ids):\n",
    "    return retrieve_batch_predictions(project_id, ids, API_KEY)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = []\n",
    "    for i in range(start_index, end_index, batch_size):\n",
    "        batch_ids = tasks_ids[i : min(i + batch_size, end_index)]\n",
    "        futures.append(executor.submit(submit_batches, batch_ids))\n",
    "\n",
    "    # collect results (or just wait for them)\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            # do something with result, e.g. log success\n",
    "        except Exception as e:\n",
    "            # handle per‚Äëbatch failures\n",
    "            logging.exception(f\"Batch failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">üí¨ **Note:**\n",
    ">\n",
    ">Use the Label Studio interface to **review and finalize annotations** for the predicted questions. These annotated questions will then be used to **automatically generate corresponding answers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Generation with MeDAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step involves setting up a project for answer generation using the questions created in the previous step.\n",
    "\n",
    "We'll set up a project, export our questions generated in the previous section and generate answers in Label Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_answer_config = '''\n",
    "<View className=\"root\">\n",
    "  <Style>\n",
    "  .root {\n",
    "    font-family: 'Roboto', sans-serif;\n",
    "    line-height: 1.6;\n",
    "    background-color: #f0f0f0;\n",
    "  }\n",
    "  .container {\n",
    "    margin: 0 auto;\n",
    "    padding: 20px;\n",
    "    background-color: #ffffff;\n",
    "    border-radius: 5px;\n",
    "    box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.1), 0 6px 20px 0 rgba(0, 0, 0, 0.1);\n",
    "  }\n",
    "  .prompt {\n",
    "    padding: 20px;\n",
    "    background-color: #0084ff;\n",
    "    color: #ffffff;\n",
    "    border-radius: 5px;\n",
    "    margin-bottom: 20px;\n",
    "    box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1), 0 3px 10px 0 rgba(0, 0, 0, 0.1);\n",
    "  }\n",
    "  .prompt-input {\n",
    "    flex-basis: 49%;\n",
    "    padding: 20px;\n",
    "    background-color: rgba(44, 62, 80, 0.9);\n",
    "    color: #ffffff;\n",
    "    border-radius: 5px;\n",
    "    box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1), 0 3px 10px 0 rgba(0, 0, 0, 0.1);\n",
    "    width: 100%;\n",
    "    border: none;\n",
    "    font-family: 'Roboto', sans-serif;\n",
    "    font-size: 16px;\n",
    "    outline: none;\n",
    "  }\n",
    "  .prompt-input:focus {\n",
    "    outline: none;\n",
    "  }\n",
    "  .prompt-input:hover {\n",
    "    background-color: rgba(52, 73, 94, 0.9);\n",
    "    cursor: pointer;\n",
    "    transition: all 0.3s ease;\n",
    "  }\n",
    "  .lsf-richtext__line:hover {\n",
    "    background: unset;\n",
    "  }\n",
    "  </Style>\n",
    "  <Text name=\"chat\" value=\"$text\" layout=\"dialogue\"/>\n",
    "  <Header value=\"Answer prompt:\"/>\n",
    "  <View className=\"prompt\">\n",
    "    <TextArea name=\"prompt\" toName=\"chat\" rows=\"4\" editable=\"true\" maxSubmissions=\"1\" showSubmitButton=\"false\"/>\n",
    "  </View>\n",
    "  <Header value=\"Proposed answer:\"/>\n",
    "  <TextArea name=\"response\" toName=\"chat\" rows=\"3\" editable=\"true\" maxSubmissions=\"1\" showSubmitButton=\"false\"/>\n",
    "</View>\n",
    "    '''\n",
    "\n",
    "\n",
    "medal_answers_project = client.projects.create(\n",
    "    title='MeDAL Answer Generation',\n",
    "    color='#617ADA',\n",
    "    description='',\n",
    "    label_config=medal_answer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export questions from our previous project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk.data_manager import Filters, Column, Type, Operator\n",
    "\n",
    "filters = Filters.create(Filters.AND, [\n",
    "    Filters.item(\n",
    "        Column.completed_at,\n",
    "        Operator.EMPTY,\n",
    "        Type.Boolean,\n",
    "        Filters.value(False)\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "view = client.views.create(\n",
    "    project=medal_questions_project.id,\n",
    "    data={\n",
    "        'title': 'Annotated Tasks',\n",
    "        'filters': filters\n",
    "    }\n",
    ")\n",
    "tab = client.views.get(id=view.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download questions from Label Studio\n",
    "annotated_tasks = list(\n",
    "    client.tasks.list(\n",
    "        view=tab.id,\n",
    "        fields='all',\n",
    "        page_size=100\n",
    "    )\n",
    ")\n",
    "\n",
    "questions_tasks = annotated_tasks\n",
    "print(len(questions_tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_tasks[0].annotations[0]['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_tasks[0].annotations[0]['result'][0]['value']['text'][0].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format as a Hugging Face dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datasets import Dataset\n",
    "\n",
    "# Extract questions\n",
    "def extract_questions_data(questions_tasks):\n",
    "    data = []\n",
    "    for task in questions_tasks:\n",
    "        for result in task.annotations[0]['result']:\n",
    "            if result['from_name'] == 'response':\n",
    "                # Extract the abstract_id\n",
    "                abstract_id = task.data['abstract_id']\n",
    "                \n",
    "                # Extract the question text and split by newlines to handle multiple questions\n",
    "                questions = result['value']['text'][0].split('\\n')\n",
    "                \n",
    "                # Store each question with its corresponding abstract_id\n",
    "                for question in questions:\n",
    "                    # Check if the question is not empty and contains at least one alphanumeric character\n",
    "                    if question.strip() and re.search('[a-zA-Z0-9]', question):\n",
    "                        data.append({'abstract_id': abstract_id, 'text': question})\n",
    "                break\n",
    "    return data\n",
    "\n",
    "extracted_questions_data = extract_questions_data(questions_tasks)\n",
    "\n",
    "questions_dataset = Dataset.from_dict({'abstract_id': [item['abstract_id'] for item in extracted_questions_data], \n",
    "                             'text': [item['text'] for item in extracted_questions_data]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review our dataset and insert it into our answers project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset to our Answers Project\n",
    "for question in questions_dataset: \n",
    "    client.tasks.create(\n",
    "        project=medal_answers_project.id,\n",
    "        data=question\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the questions curation, we also need a strong prompt for generating the answers to these questions. Here is a sample prompt that can be used.\n",
    "\n",
    "```txt\n",
    "You are a medical expert. Answer the following question using only the information provided in the accompanying text. Follow these strict rules:\n",
    "\n",
    "- Output only the final answer.\n",
    "- Do not restate the question.\n",
    "- Do not explain, elaborate, speculate, or add context.\n",
    "- Do not add formatting, markdown, notes, or instructions.\n",
    "- Only use content explicitly stated in the text.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß To set up the ML Backend for answer generation, first stop the backend server that was previously used for question generation.\n",
    "Then, open a terminal in the Label Studio environment and run the following commands:\n",
    "```bash\n",
    "$ cd /work/label-studio/ml_backend\n",
    "$ source setup_answers.sh\n",
    "$ gunicorn _wsgi:app --bind 0.0.0.0:9090 --workers 10 --timeout 120 --graceful-timeout 30 --keep-alive 5\n",
    "```\n",
    "This will launch a new ML backend configured for generating answers. Again, connect the backend to the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk import Client\n",
    "\n",
    "def get_project_task_ids(label_studio_host, api_token, project_id):\n",
    "    client = Client(url=label_studio_host, api_key=api_token)\n",
    "    project = client.get_project(project_id)\n",
    "    task_ids = project.get_tasks_ids()\n",
    "    return task_ids\n",
    "\n",
    "project_id = medal_answers_project.id\n",
    "\n",
    "tasks_ids = get_project_task_ids(LABEL_STUDIO_URL, API_KEY, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tasks_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def retrieve_batch_predictions(project_id, task_ids, api_key):\n",
    "    url = f\"{LABEL_STUDIO_URL}/api/dm/actions?id=retrieve_tasks_predictions&project={project_id}\"\n",
    "    headers = {\n",
    "        'Authorization': f'Token {api_key}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    data = {\n",
    "        'selectedItems': {\n",
    "            'all': False,\n",
    "            'included': task_ids\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "batch_size   = 15  # compare with Triton Server MAX_BATCH_SIZE and INSTANCE_COUNT\n",
    "start_index  = 0\n",
    "end_index    = 50000\n",
    "max_workers  = 8   # tune this based on how many parallel requests your server can handle\n",
    "project_id = medal_answers_project.id\n",
    "\n",
    "def submit_batches(ids):\n",
    "    return retrieve_batch_predictions(project_id, ids, API_KEY)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = []\n",
    "    for i in range(start_index, end_index, batch_size):\n",
    "        batch_ids = tasks_ids[i : min(i + batch_size, end_index)]\n",
    "        futures.append(executor.submit(submit_batches, batch_ids))\n",
    "\n",
    "    # collect results (or just wait for them)\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            # do something with result, e.g. log success\n",
    "        except Exception as e:\n",
    "            # handle per‚Äëbatch failures\n",
    "            logging.exception(f\"Batch failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">üí¨ Note:\n",
    ">\n",
    ">Use the Label Studio interface to **review and validate the predicted answers**. The finalized annotations will be used to **assemble the synthetic Q&A dataset** for fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate Q&A Dataset\n",
    "\n",
    "Once question-answer pairs are generated and refined, download the synthetic dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk.data_manager import Filters, Column, Type, Operator\n",
    "\n",
    "filters = Filters.create(Filters.AND, [\n",
    "    Filters.item(\n",
    "        Column.completed_at,\n",
    "        Operator.EMPTY,\n",
    "        Type.Boolean,\n",
    "        Filters.value(False)\n",
    "    )\n",
    "])\n",
    "\n",
    "view = client.views.create(\n",
    "    project=medal_answers_project.id,\n",
    "    data={\n",
    "        'title': 'Annotated Tasks',\n",
    "        'filters': filters\n",
    "    }\n",
    ")\n",
    "tab = client.views.get(id=view.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download answers from Label Studio\n",
    "answers_tasks = list(\n",
    "    client.tasks.list(\n",
    "        view=tab.id,\n",
    "        fields='all',\n",
    "        page_size=100\n",
    "    )\n",
    ")\n",
    "print(len(answers_tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Q&A dataset\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "def extract_answers_data(answers_tasks):\n",
    "    data = []\n",
    "    for task in answers_tasks:\n",
    "        for result in task.annotations[0]['result']:\n",
    "            if result['from_name'] == 'response':\n",
    "                # Extract the abstract_id\n",
    "                abstract_id = task.data['abstract_id']\n",
    "                \n",
    "                # Extract the question text and split by newlines to handle multiple questions\n",
    "                answer = result['value']['text'][0]\n",
    "                question = task.data['text']\n",
    "                \n",
    "                # Store each question with its corresponding abstract_id\n",
    "                data.append({'abstract_id': abstract_id, 'question': question, 'answer': answer})\n",
    "    return data\n",
    "\n",
    "extracted_answers_data = extract_answers_data(answers_tasks)\n",
    "\n",
    "qa_dataset = Dataset.from_dict({'abstract_id': [item['abstract_id'] for item in extracted_answers_data], \n",
    "                             'question': [item['question'] for item in extracted_answers_data],\n",
    "                             'answer': [item['answer'] for item in extracted_answers_data]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to a JSON Lines file\n",
    "qa_dataset.to_json(\"datasets/medal-qa_synthetic_dataset_v1.jsonl\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
